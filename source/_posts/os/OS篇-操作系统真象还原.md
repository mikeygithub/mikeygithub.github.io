---
title: OS篇-操作系统真象还原
index_img: 'https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/czxt-zxhy.png'
hide: false
date: 2021-02-21 22:09:25
category: 操作系统
tags: 操作系统
---

# 环境准备

- VirtualBox
- Linux
- Bochs

# 准备知识

## 软件是如何访问硬件的

>硬件是各种各样的,发展速度还是非常快的。各个硬件都有自己的个性,操作系统不可能及时更新各种硬件的驱动方法吧。比如,刚出来某个新硬件,OS 开发者们便开始为其写驱动,这不太现实,会把人累死的。于是乎,便出现了各种硬件适配设备,这就是 IO 接口。接口其实就是标准,大家生产出来的硬件按照这个标准工作就实现了通用。

>硬件在输入输出上大体分为串行和并行,相应的接口也就是串行接口和并行接口。串行硬件通过串行接口与 CPU 通信,反过来也是,CPU 通过串行接口与串行设备数据传输。并行设备的访问类似,只不过是通过并行接口进行的。

访问外部硬件有两个方式。

- (1)将某个外设的内存映射到一定范围的地址空间中,CPU 通过地址总线访问该内存区域时会落到外设的内存中,这种映射让 CPU 访问外设的内存就如同访问主板上的物理内存一样。有的设备是这样做的,比如显卡,显卡是显示器的适配器,CPU 不直接和显示器交互,它只和显卡通信。显卡上有片内存叫显存,它被映射到主机物理内存上的低端 1MB 的 0xB8000~0xBFFFF。CPU 访问这片内存就是访问显存,往这片内存上写字节便是往屏幕上打印内容。看上去这么高大上的做法是怎么实现的,这个我们就不关心了,前面说过,计算机中处处是分层,我们要充分相信上一层的工作。
- (2)外设是通过 IO 接口与 CPU 通信的,CPU 访问外设,就是访问 IO 接口,由 IO 接口将信息传递给另一端的外设,也就是说,CPU 从来不知道有这些设备的存在,它只知道自己操作的 IO 接口,你看,处处体现着分层。于是问题来了,如何访问到 IO 接口呢,答案就是 IO 接口上面有一些寄存器,访问 IO 接口本质上就是访问这些寄存器,这些寄存器就是人们常说的端口。这些端口是人家 IO 接口给咱们提供的接口。人家接口电路也有自己的思维(系统),看到寄存器中写了什么就做出相应的反应。接口提供接口,哈哈,有意思。不过这是人家的约定,没有约定就乱了,各干各的,大家都累,咱们只要遵循人家的规定就能访问成功。

## 应用程序

> 和操作系统是如何配合到一起的 应用程序是软件（似乎是废话，别急，往后看），操作系统也是软件。CPU 会将它们一视同仁，甚至， CPU 不知道自己在执行的程序是操作系统，还是一般应用软件，CPU 只知道去 cs：ip 寄存器中指向的内 存取指令并执行，它不知道什么是操作系统，也无需知道。 操作系统是人想出来的，为了让自己管理计算机方便而创造出来的一套管理办法。 应用程序要用某种语言编写，而语言又是编译器来提供的。其实根本就没有什么语言，有的只是编译 器。是编译器决定怎样解释某种关键字及某种语法。语言只是编译器和大家的约定，只要写入这样的代码， 编译器便将其翻译成某种机器指令，翻译成什么样取决于编译器的行为，和语言无关，比如说 C 语言的 printf 函数，它的功能不是说一定要把字符打印到屏幕上，这要看编译器对这种关键字的处理。 编译器提供了一套库函数，库函数中又有封装的系统调用，这样的代码集合称之为运行库。C 语言的 运行库称为 C 运行库，就是所谓的 CRT（C Runtime Library）。 应用程序加上操作系统提供功能才算是完整的程序。由于有了操作系统的支持，一些现成的东西已经摆 在那了，但这些是属于操作系统的，不是应用程序的，所以咱们平时所写的应用程序只是半成品，需要调用 操作系统提供好的函数才能完整地做成一件事，而这个函数便是系统调用。 用户态与内核态是对 CPU 来讲的，是指 CPU 运行在用户态（特权 3 级）还是内核态（特权 0 级）， 很多人误以为是对用户进程来讲的。 用户进程陷入内核态是指：由于内部或外部中断发生，当前进程被暂时终止执行，其上下文被内核的 中断程序保存起来后，开始执行一段内核的代码。是内核的代码，不是用户程序在内核的代码，用户代码 怎么可能在内核中存在，所以“用户态与内核态”是对 CPU 来说的。 当应用程序陷入内核后，它自己已经下 CPU 了，以后发生的事，应用程序完全不知道，它的上下文环境已 经被保存到自己的 0 特权级栈中了，那时在 CPU 上运行的程序已经是内核程序了。所以要清楚，内核代码并不 是成了应用程序的内核化身，操作系统是独立的部分，用户进程永远不会因为进入内核态而变身为操作系统了。 异步社区会员 databus(17602509427) 专享 尊重版权 第 0 章 一些你可能正感到迷惑的问题 4 应用程序是通过系统调用来和操作系统配合完成某项功能的，有人可能会问：我写应用程序时从来没 写什么系统调用的代码啊。这是因为你用到的标准库帮你完成了这些事，库中提供的函数其实都已经封装 好了系统调用，你需要跟下代码才会看到。其实也可以跨过标准库直接执行系统调用，对于 Linux 系统来 说，直接嵌入汇编代码“int 0x80”便可以直接执行系统调用，当然要提前设置好系统调用子功能号，该 子功能号用寄存器 eax 存储。 会不会有人又问，编译器怎么知道系统调用接口是什么，哈哈，您想啊，下载编译器时，是不是要选择系 统版本，编译器在设计时也要知道自己将来运行在哪个系统平台上，所以这都是和系统绑定好的，各个操作系 统都有自己的系统调用号，编译器厂商在代码中已经把宿主系统的系统调用号写死了，没什么神奇的。

## 用户态与内核态

>用户态与内核态是对 CPU 来讲的,是指 CPU 运行在用户态(特权 3 级)还是内核态(特权 0 级), 很多人误以为是对用户进程来讲的。


## 陷入内核

>如果把软件分层的话, 最外圈是应用程序,里面是操作系统,如图 0-1 所示。 应用程序处于特权级 3,操作系统内核处于特权级 0。当用户程序欲 访问系统资源时(无论是硬件,还是内核数据结构),它需要进行系统调用。这样 CPU 便进入了内核态,也称管态。看图中凹下去的部分,是不 是有陷进去的感觉,这就是“陷入内核”。

<img src="https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222102733078.png" alt="image-20210222102733078" style="zoom:25%;" />

## 内存访问为什么要分段

按理说咱们应该先看看段是什么，不过了解段是什么之前，先看看内存是什么样子，如图 

![image-20210222230327991](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222230327991.png)

内存按访问方式来看，其结构就如同上面的长方形带子，地址依次升高。为了解释问题更明白，我们 假设还在实模式下，如果读者不清楚什么是实模式也不要紧，这并不影响理解段是 什么，故暂且先忽略。

> 内存是随机读写设备，即访问其内部任何一处，不需要从头开始找，只要直接 给出其地址便可。如访问内存 0xC00，只要将此地址写入地址总线便可。问题来了， 分段是内存访问机制，是给 CPU 用的访问内存的方式，只有 CPU 才关注段，那为 什么 CPU 要用段呢，也就是为什么 CPU 非得将内存分成一段一段的才能访问呢？ 

> 说来话长，现实行业中有很多问题都是历史遗留问题，计算机行业也不能例外。 分段是从 CPU 8086 开始的，限于技术和经济，那时候电脑还是非常昂贵的东西， 所以 CPU 和寄存器等宽度都是 16 位的，并不是像今天这样寄存器已经扩展到 64 位，当然编译器用的最多的还是 32 位。16 位寄存器意味着其可存储的数字范围是 2 的 16 次方，即 65536 字节，64KB。那时的计算机没有虚拟地址之说，只有物理 地址，访问任何存储单元都直接给出物理地址。 

> 编译器在编译程序时，肯定要根据 CPU 访问内存的规则将代码编译成机器指令，这样编译出来的程序才能 在该 CPU 上运行无误，所以说，在直接以绝对物理地址访问内存的 CPU 上运行程序，该程序中指令的地址也必 须得是绝对物理地址。总之，要想在该硬件上运行，就要遵从该硬件的规则，操作系统和编译器也无一例外。 若加载程序运行，不管其是内核程序，还是用户程序，程序中的地址若都是绝对物理地址，那该程序必须放 在内存中固定的地方，于是，两个编译出来地址相同的用户程序还真没法同时运行，只能运行一个。于是伟大的 计算机前辈们用分段的方式解决了这一问题，让 CPU 采用“段基址+段内偏移地址”的方式来访问任意内存。这 样的好处是程序可以重定位了，尽管程序指令中给的是绝对物理地址，但终究可以同时运行多个程序了。 

> 什么是重定位呢，简单来说就是将程序中指令的地址改写成另外一个地址，但该地址处的内容还是原

CPU 采用“段基址+段内偏移地址”的形式访问内存，就需要专门提供段基址寄存器，这些是 cs、ds、 es 等。程序中需要用到哪块内存，只要先加载合适的段到段基址寄存器中，再给出相对于该段基址的偏移 地址便可，CPU 中的地址单元会将这两个地址相加后的结果用于内存访问，送上地址总线。 

> 注意，很多读者都觉得段基址一定得是 65536 的倍数（16 位段基址寄存器的容量），这个真的不用， 段基址可以是任意的。这就是段可以重叠的原因。 

> 举个例子，看图 0-2，假设段基址为 0xC00，要想访问物理内存 0xC01，就要将用 0xC00：0x01 的方 式来访问才行。若将段基址改为 0xc01，还是访问 0xC01，就要用 0xC01：0x00 的方式来访问。同样，若 想访问物理内存 0xC04，段基址和段内偏移的组合可以是：0xC01：0x03、0xC02：0x02、0xC00：0xC04 等，总之要想访问某个物理地址，只要凑出合适的段基地址和段内偏移地址，其和为该物理地址就行了。 这时估计有人会问这样行不行，0xC05：-1，能这样提问的同学都是求知欲极强的，可以自己试一下。 说了这么多，我想告诉你的是只要程序分了段，把整个段平移到任何位置后，段内的地址相对于段基 址是不变的，无论段基址是多少，只要给出段内偏移地址，CPU 就能访问到正确的指令。于是加载用户 程序时，只要将整个段的内容复制到新的位置，再将段基址寄存器中的地址改成该地址，程序便可准确无 误地运行，因为程序中用的是段内偏移地址，相对于新的段基址， 该偏移地址处的内存内容还是一样的，如图 。

![image-20210222231547254](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222231547254.png)

 所以说，程序分段首先是为了重定位，我说的是首先，下面 还有其他理由呢。 偏移地址也要存入寄存器，而那时的寄存器是 16 位的，也就 是一个段最多可以访问到 64KB。而那时的内存再小也有 1MB， 改变段基址，由一个段变为另一个段，就像一个段在内存中飘移， 采用这种在内存中来回挪位置的方式可以访问到任意内存位置。 所以说，程序分段又是为了将大内存分成可以访问的小段， 通过这样变通的方法便能够访问到所有内存了。 但想一想，1M 是 2 的 20 次方，1MB 内存需要 20 位的地址 才能访问到，如何做到用 16 位寄存器访问 20 位地址空间呢？ 在 8086 的寻址方式中，有基址寻址，这是用基址寄存器 bx 或 bp 来提供偏移地址的，如“mov [bx]， 0x5；”指令便是将立即数 0x5 存入 ds：bx 指向的内存。 大家看，bx 寄存器是 16 位的，它最大只能表示 0～0xFFFF 的地址空间，即 64KB，也就是单一的一个寄存 器无法表示 20 位的地址空间—1MB。也许有人会说，段基址和段内偏移地址都搞到最大，都为 0xFFFF，对 不起，即使不溢出的话，其结果也只是由 16 位变成了 17 位，即两个 n 位的数字无论多大，其相加的结果也超不 过 n+1 位，因为即使是两个相同的数相加，其结果相当于乘以 2，也就是左移一位而已，依然无法访问 20 位的 地址空间。也许读者又有好建议了：CPU 的寻址方式又不是仅仅这一种，上面的限制是因为寄存器是 16 位，只 要不全部通过寄存器不就行了吗。既然段寄存器必须得用，那就在偏移地址上下功夫，不要把偏移地址写在寄存 器里了，把它直接写成 20 位立即数不就行啦。例如 mov ax，[0x12345]，这样最终的地址是 ds+0x12345，肯定 是 20 位，解决啦。不错，这种是直接寻址方式，至少道理上讲得通，这是通过编程技巧来突破这一瓶颈的，能 想到这一点我觉得非常 nice。但是作为一个严谨的 CPU，既然宣称支持了通过寄存器来寻址，那就要能够自圆 其说才行，不能靠程序员的软实力来克服 CPU 自身的缺陷。于是，一个大胆的想法出现了。 16 位的寄存器最多访问到 64KB 大小的内存。虽然 1MB 内存中可容纳 1MB/64KB=16 个最大段，但 这只是可以容纳而已，并不是说可以访问到。16 位的寄存器超过 0xffff 后将会回卷到 0，又从 0 重新开始。 20 位宽度的内存地址空间必然只能由 20 位宽度的地址来访问。问题又来了，在当时只有 16 位寄存器的 情况下是如何做到访问 20 位地址空间的呢？ 这是因为 CPU 设计者在地址处理单元中动了手脚，该地址部件接到“段基址+段内偏移地址”的地址后， 自动将段基址乘以 16，即左移了 4 位，然后再和 16 位的段内偏移地址相加，这下地址变成了 20 位了吧，行啦，有了 20 位的地址便可以访问 20 位的空间，可以在 1MB 空间内自由翱翔了。

## 代码中为什么分为代码段、数据段？这和内存访问机制中的 段是一回事吗

> 首先，程序不是一定要分段才能运行的，分段只是为了使程序更加优美。就像用饭盒装饭菜一样，完 全可以将很多菜和米饭混合在一起，或者搅拌成一体，哈哈，但这样可能就没什么胃口啦。如果饭盒中有 好多小格子，方便将不同的菜和饭区分存放，这样会让我们胃口大开增加食欲。 x86 平台的处理器是必须要用分段机制访问内存的，正因为如此，处理器才提供了段寄存器，用来指定待访 问的内存段起始地址。我们这里讨论的程序代码中的段（用 section 或 segment 来定义的段，不同汇编编译器提 供的关键字有所区别，功能是一样的）和内存访问机制中的段本质上是一回事。在硬件的内存访问机制中，处理 器要用硬件—段寄存器，指向软件—程序代码中用 section 或 segment 以软件形式所定义的内存段。 分段是必然的，只是在平坦模型下，硬件段寄存器中指向的内存段为最大的 4GB，而在多段模式下编 程，硬件段寄存器中指向的内存段大小不一。 对于在代码中的分段，有的是操作系统做的，有的是程序员自己划分的。如果是在多段模型下编程， 我们必然会在源码中定义多个段，然后需要不断地切换段寄存器所指向的段，这样才能访问到不同段中的 数据，所以说，在多段模型下的程序分段是程序员人为划分的。如果是在平坦模型下编程，操作系统将整 个 4GB 内存都放在同一个段中，我们就不需要来回切换段寄存器所指向的段。对于代码中是否要分段， 这取决于操作系统是否在平坦模型下。 一般的高级语言不允许程序员自己将代码分成各种各样的段，这是因为其所用的编译器是针对某个操 作系统编写的，该操作系统采用的是平坦模型，所以该编译器要编译出适合此操作系统加载运行的程序。 由于处理器支持了具有分页机制的虚拟内存，操作系统也采用了分页模型，因此编译器会将程序按内容划 分成代码段和数据段，如编译器 gcc 会把 C 语言写出的程序划分成代码段、数据段、栈段、.bss 段、堆等 部分。这会由操作系统将编译器编译出来的用户程序中的各个段分配到不同的物理内存上。对于目前咱们 用高级语言编码来说，我们之所以不用关心如何将程序分段，正是由于编译器按平坦模型编译，而程序所 依赖的操作系统又采用了虚拟内存管理，即处理器的分页机制。像汇编这种低级语言允许程序员为自己的 程序分段，能够灵活地编排布局，这就属于人为将程序分成段了，也就是采用多段模型编程。 这么说似乎不是很清楚，一会再用例子和大伙儿解释就明白了。在这之前，先和大家明确一件事。 CPU 是个自动化程度极高的芯片，就像心脏一样，给它一个初始的收缩，它将永远地跳下去。突然 想到 Intel 的广告词：给你一颗奔腾的心。 只要给出 CPU 第一个指令的起始地址，CPU 在它执行本指令的同时，它会自动获取下一条的地址， 然后重复上述过程，继续执行，继续取址。假如执行的每条指令都正确，没有异常发生的话，我想它可以 运行到世界的尽头，能让它停下来的唯一条件就是断电。 它为什么能够取得下一条指令地址？也就是说为什么知道下一条指令在哪里。这是因为程序中的指令 都是挨着的，彼此之间无空隙。有同学可能会问，程序中不是有对齐这回事吗？为了对齐，编译器在程序 中塞了好多 0。是的，对齐确实是让程序中出现了好多空隙，但这些空隙是数据间的空隙，指令间不存在 空隙，下一条指令的地址是按照前面指令的尺寸大小排下来的，这就是 Intel 处理器的程序计数器 cs：eip 能够自动获得下一条指令的原理，即将当前 eip 中的地址加上当前指令机器码的大小便是内存中下一条指 令的起始地址。即使指令间有空隙或其他非指令的数据，这也仅仅是在物理上将其断开了，依然可以用 jmp 指令将非指令部分跳过以保持指令在逻辑上连续，我们在后面会通过实例验证这一原理。 为了让程序内指令接连不断地执行，要把指令全部排在一起，形成一片连续的指令区域，这就是代码 段。这样 CPU 肯定能接连不断地执行下去。指令是由操作码和操作数组成的，这对于数据也一样，程序 运行不仅要有操作码，也得有操作数，操作数就是指程序中的数据。把数据连续地并排在一起存储形成的段落，就称为数据段。 指令大小是由实际指令的操作码决定的，也就是说 CPU 在译码阶段拿到了操作码后，就知道实际指令所占 的大小。其实说来说去，本质上就是在解释地址是怎么来的。

```
1 mov ds,ax
2 mov ax,[var]
3 label：
4 jmp label
5 var dw 0x99 
```

本示例一共就 5 行，简单纯粹为演示。将其编译为二进制文件，程序内容是： 

>8E D8 A1 07 00 EB FE 99 00

![image-20210222234118777](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222234118777.png)

 0-1 第 1 行，地址 0 处的指令是“mov ds，ax”，其机器码是 8ED8，这是十六进制表示，可见其大 小是 2 字节。前面说过，下一条指令的地址是按照前面指令的尺寸排下来的，那第 2 行指令的起始地址是 0+2=2。在第 2 行的地址列中，地址确实是 2。这不是我故意写上去的，编译器真的就是这样编排的。第 2 列的指令是“mov ax，[0x7]”（0x7 是变量 var 经过编译后的地址），其机器码是 A10700，这是 3 字节大小。 所以第 3 条指令的地址是 2+3=5。后面的指令地址也是这样推算的。程序虽然很短，但麻雀虽小，五脏俱 全，完美展示了程序中代码紧凑无隙的布局。 现在大伙儿明白为什么 CPU 能源源不断获取到指令了吧，如前所述，原因首先是指令是连续紧凑的， 其次是通过指令机器码能够判断当前指令长度，当前指令地址+当前指令长度=下一条指令地址。 上面给出的例子，其指令在物理上是连续的，其实在 CPU 眼里，只要指令逻辑上是连续的就可以，没必要 一定得是物理上连续。所以，明确一点，即使数据和代码在物理上混在一起，程序也是可以运行的，这并不意味 着指令被数据“断开”了。只要程序中有指令能够跨过这些数据就行啦，最典型的就是用 jmp 跳过数据区。 比如这样的汇编代码：

```
1 jmp start ;跳转到第三行的 start，这是 CPU 直接执行的指令
2 var dd 1 ;定义变量 var 并赋值为 1。分配变量不是 CPU 的工作 ;汇编器负责分配空间并为变量编址
3 start： ;标号名为 start，会被汇编器翻译为某个地址
4 mov ax,0 ；将 ax 赋值为 0 
```

这几行代码没有实际意义，只是为了解释清楚问题，咱们只要关注在第 2 行的定义变量 var 之前为什 么要 jmp start。如果将上面的汇编代码按纯二进制编译，如果不加第 1 行的 jmp，CPU 也许会发出异常， 显示无效指令，也许不知道执行到哪里去了。因为 CPU 只会执行 cs：ip 中的指令，这两个寄存器记录的 是下一条待执行指令的地址，下一个地址 var 处的值为 1，显然我们从定义中看出这只是数据，但指令和 数据都是二进制数字，CPU 可分不出这是指令，还是数据。保不准某些“数据”误打误撞恰恰是某种指 令也说不定。既然 var 是我们定义的数据，那么必须加上 jmp start 跳过这个 var 所占的空间才可以。

> 加个 jmp 指令，这样做一点都不影响运行，只不过这样写出来的程序，其中引用的地址大部分是不连 续的，也就是程序在取地址时会显得跳来跳去。就美观层面上看，这样的结构显得很凌乱，不利于程序员 阅读与维护。如果把第 2 行的 var 换到第 1 行，数据和代码就分开了，没有混在一起，标号都不用了，代 码简洁多了，如下。

```
var dd 1
mov ax,0 
```

做过开发的同学都清楚，尽量把同一属性的数据放在一起，这样易于维护。这一点类似于 MVC，在程序 逻辑中把模型、视图、控制这三部分分开，这样更新各部分时，不会影响到其他模块。 将数据和代码分开的好处有三点。 第一，可以为它们赋予不同的属性。 例如数据本身是需要修改的，所以数据就需要有可写的属性，不让数据段可写，那程序根本就无法执 行啦。程序中的代码是不能被更改的，这样就要求代码段具备只读的属性。真要是在运行过程中程序的下 一条指令被修改了，谁知道会产生什么样的灾难。 第二，为了提高 CPU 内部缓存的命中率。 大伙儿知道，缓存起作用的原因是程序的局部性原理。在 CPU 内部也有缓存机制，将程序中的指令 和数据分离，这有利于增强程序的局部性。CPU 内部有针对数据和针对指令的两种缓存机制，因此，将 数据和代码分开存储将使程序运行得更快。 第三，节省内存。 程序中存在一些只读的部分，比如代码，当一个程序的多个副本同时运行时（比如同时执行多个 ls 命令时），没必要在内存中同时存在多个相同的代码段，这将浪费有限的物理内存资源，只要把这一个代 码段共享就可以了。 后两点较容易理解，咱们深入讨论下第一点，不知您有没有想过，数据段或代码段的属性是谁给添加上的呢， 是谁又去根据属性保护程序的呢，是程序员吗？是编译器吗？是操作系统吗？还是 CPU 一级的硬件支持？ 首先肯定不是程序员，人家操作系统设计人员为了让程序员编写程序更加容易，肯定不会让他们分心去 处理这些与业务逻辑无关的事。看看编译器为我们做了什么，它将程序中那些只读的代码编译出来后，放在 一片连续的区域，这个区域叫代码段。将那些已经初始化的数据也放在一片连续的区域，这个区域叫数据段， 那些具有全局属性的但又未初始化的数据放在 bss 段。总之，程序中段的类型可多了，用“readelf –e elf”命 令便可以看到很多段的类型，感兴趣的读者请自行查阅。好了，编译器的工作到此就完事了，显然，数据段 和代码段的属性到现在还没有体现出来。 先看 CPU 为我们提供了哪些原生的支持。在保护模式下，有这样一个数据结构，它叫全局描述符表（Global Descriptor Table，GDT），这个表中的每一项称为段描述符。先递归学习一下，什么是描述符？描述符就是描 述某种数据的数据结构，是元信息，属于数据的数据。就像人们的身份证，上面有写性别、出生日期、地址等 描述个人情况的信息。在段描述符中有段的属性位，在以后的章节中可以看到，其实是有 2 个，一个是 S 字 段，占 1bit 大小，另外一个是占 4bit 大小的 TYPE 字段，这两个字段配合在一起使用就能组合出各种属性， 如只读、向下扩展、只执行等。提供归提供，可得有人去填写这张表啊，谁来做这事呢，有请操作系统登场。 接着看操作系统为我们做了什么。 操作系统在让 CPU 进入保护模式之前，首先要准备好 GDT，也就是要设置好 GDT 的相关项，填写好 段描述符。段描述符填写成什么样，段具备什么样的属性，这完全取决于操作系统了，在这里大家只要知道， 段描述符中的 S 字段和 TYPE 字段负责该段的属性，也就是该属性与安全相关。 说到这里，答案似乎浮出水面了。 （1）编译器负责挑选出数据具备的属性，从而根据属性将程序片段分类，比如，划分出了只读属性的 代码段和可写属性的数据段。再补充一下，编译器并没有让段具备某种属性，对于代码段，编译器所做的 只是将代码归类到一起而已，也就是将程序中的有关代码的多个 section 合并成一个大的 segment（这就是 我们所说的代码段），它并没有为代码段添加额外的信息。



（2）操作系统通过设置 GDT 全局描述符表来构建段描述符，在段描述符中指定段的位置、大小及属 性（包括 S 字段和 TYPE 字段）。也就是说，操作系统认为代码应该是只读的，所以给用来指向代码段的 那个段描述符设置了只读的属性，这才是真正给段添加属性的地方。 （3）CPU 中的段寄存器提前被操作系统赋予相应的选择子（后面章节会讲什么是选择子，暂时将其 理解为相当于段基址），从而确定了指向的段。在执行指令时，会根据该段的属性来判断指令的行为，若 有返回则发出异常。 总之，编译器、操作系统、CPU 三个配合在一起才能对程序保护，检测出指令中的违规行为。如果 GDT 中的代码段描述符具备可写的属性，那编译器再怎么划分代码段都没有用，有判断权利的只有 CPU。 好，现在大家对 GDT 有个感性认识，随着以后章节中讲 GDT 的时候，大家就会有深刻的理解了。 以上说明了程序按内容分段的原因，那么编译器编译出来的段和内存访问中的段是一回事吗？ 其实算一回事，也不算一回事。怎么说呢，我觉得当初 Intel 公司在设计 CPU 时，其采用分段机制访问内 存的原因，肯定不是为了上层软件的优美，毕竟那只是逻辑上的东西。那为什么也算一回事呢？ 分析一下，编译出来的代码段是指一片连续的内存区域。这个段有自己的起始地址，也有自己的大小 范围。用户进程中的段，只是为了便于管理，而编译器或程序员在“美学方面”做出的规划，本质上它并 不是 CPU 用于内存访问的段，但它们都是描述了一段内存，而且程序中的段，其起始地址和大小可以理 解为 CPU 访问内存分段策略中的“段基址：段内偏移地址”，这么说来，至少它们很接近了，让我们更近 一步：程序是可以被人为划分成段的，并且可以将划分出来的段地址加载到段寄存器中，见下面的代码

```
 1 section my_code vstart=0
 2 ;通过远跳转的方式给代码段寄存器 CS 赋值 0x90
 3 jmp 0x90:start
 4 start: ;标号 start 只是为了 jmp 跳到下一条指令
 5
 6 ;初始化数据段寄存器 DS
 7 mov ax,section.my_data.start
 8 add ax,0x900 ;加 0x900 是因为本程序会被 mbr 加载到内存 0x900 处
 9 shr ax,4 ;提前右移 4 位,因为段基址会被 CPU 段部件左移 4 位
10 mov ds,ax
11
12 ;初始化栈段寄存器 SS
13 mov ax,section.my_stack.start
14 add ax,0x900 ;加 0x900 是因为本程序会被 mbr 加载到内存 0x900 处
15 shr ax,4 ;提前右移 4 位,因为段基址会被 CPU 段部件左移 4 位
16 mov ss,ax
17 mov sp,stack_top ;初始化栈指针
18
19 ;此时 CS､ DS､ SS 段寄存器已经初始化完成,下面开始正式工作
20 push word [var2] ;变量名 var2 编译后变成 0x4
21 jmp $
22
23 ;自定义的数据段
24 section my_data align=16 vstart=0
25 var1 dd 0x1
26 var2 dd 0x6
27
28 ;自定义的栈段
29 section my_stack align=16 vstart=0
30 times 128 db 0
31 stack_top: ;此处用于栈顶,标号作用域是当前 section,;以当前 section 的 vstart 为基数
```

其中自定义了三个段，为了和标准的段名（.code、.data 等）有所区 别，这里代码段取名为 my_code，数据段取名为 my_data，栈段取名为 my_stack。这段代码是由 MBR 加 载到物理内存地址 0x900 后，mbr 通过“jmp 0x900”跳过来的，我们的想法是让各段寄存器左移 4 位后 的段基址与程序中各分段实际内存位置相同，所以对于代码段，希望其基址是 0x900，故代码段 CS 的值 为 0x90（在实模式下，由 CPU 的段部件将其左移 4 位后变成 0x900，所以要初始化成左移 4 位前的值）。



> 但没有办法直接为 CS 寄存器赋值，所以在代码 0-1 开头，用“jmp 0x90：0”初始化了程序计数器 CS 和 IP。这样段寄存器 CS 就是程序中咱们自己划分的代码段了。 在此提醒一下，各 section 中的定义都有 align=16 和 vstart=0，这是用来指定各 section 按 16 位对齐的， 各 section 的起始地址是 16 的整数倍，即用十六进制表示的话，最后一位是 0。所以右移操作如第 9 行的 shr ax，4，结果才是正确的，只是把 0 移出去了。否则不加 align=16 的话，section 的地址不能保证是 16 的整数倍，右移 4 位可能会丢数据。vstart=0 是指定各 section 内数据或指令的地址以 0 为起始编号，这样 做为段内偏移地址时更方便。具体 vstart 内容请参阅本书相应章节。 第 6～10 行是初始化数据段寄存器 DS，是用程序中自已划分的段 my_data 的地址来初始化的。由于 代码 0-1 本身是脱离操作系统的程序，是 MBR 将其加载到 0x900 后通过跳转指令“jmp 0x900”跳入执行 的，所以要将 my_data 在文件内的地址 section.my_data.start 加上 0x900 才是最终在内存中的真实地址。右 移 4 位的原因同代码段相同，都是 CPU 的段部件会自动将段基址左移 4 位，故提前右移 4 位。此地址作 为段基址赋值给 DS，这样段寄存器 DS 中的值是程序中咱们自己划分的数据段了。 第 12～17 行是初始化栈段寄存器，原理和数据段差不多，唯一区别是栈段初始化多了个针指针 SP， 为它初始化的值 stack_top 是最后一行，因为栈指针在使用过程中指向的地址越来越低，所以初始化时一 定得是栈段的最高地址。 经过代码段、数据段、栈段的初始化，CPU 中的段寄存器 CS、DS、SS 都是指向程序中咱们自己划 分的段地址，之后 CPU 的内存分段机制“段基址：段内偏移地址”，段基址就是程序中咱们自己划分的段， 段内偏移地址都是各自定义段内的指令和数据地址，由于在 section 中有 vstart=0 限制，地址都是从 0 开始 编号的。所以，程序中的分段和 CPU 内存访问的分段又是一回事。 让我们对此感到疑惑的原因，可能是我们一般都是用高级语言开发程序，在高级语言中，程序分 段这种工作不由我们控制，是由编译器在编译阶段完成的。而且现代操作系统都是在平坦模型（整个 4GB 空间为 1 个段）下工作，编译器也是按照平坦模型为程序布局，程序中的代码和数据都在同一个 段中整齐排列。大家可以用 readelf –e /bin/ls 查看一下 ls 命令，结果太长，就不截图啦。咱们主要关 注三段内容。 y Section Headers：列出了程序中所有的 section，这些 section 是 gcc 编译器帮忙划分的。 y Program Headers：列出了程序中的段，即 segment，这是程序中 section 合并后的结果。 y Section to Segment mapping：列出了一个 segment 中包含了哪些 section。 有关 section 和 segment 的内容请参见本书相关章节。 在 Section Headers 和 Program Headers 中您会发现，这些分段都是按照地址由低到高在 4GB 空间中连 续整洁地分布的，在平坦模型下和谐融洽。 显然，不用程序员手工分段，并且采用平坦模型，这种操作上的“隔离”固然让我们更加方便，但也让我 们更加感到进程空间布局的神秘。如果程序分段像代码 0-1 那样地直白、亲民，大家肯定不会感到迷惑了。其实 我想说的是无论是否为平坦模型，程序中的分段和 CPU 中的内存分段机制，它们属于物品与容器的关系。 举个例子，程序中划分的段相当于各种水果，比如代码段相当于 香蕉，数据段相当于葡萄，栈段相当于西瓜。CPU 内存分段策略中的 段寄存器相当于盛水果的盘子。可以用一个大盘子将各种水果都放进 来，但依然是分门别类地摆放，不能失去美感混成一锅粥，这就是段 大小为 4GB 的平坦模型。也可以把每种水果分别放在一个小盘子里一 块儿端上来，这就是普通的分段模型，如图

![image-20210222234447598](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222234447598.png)

> 总结一下，程序中的段只是逻辑上的划分，用于不同数据的归类， 但是可以用 CPU 中的段寄存器直接指向它们，然后用内存分段机制去 访问程序中的段，在这一点上看，它们很像相片和相框的关系：程序 中的段是内存中的内容，相当于相片，属于被展示的内容，而内存分段机制则是访问内存的手段，相当于 相框，有了相框，照片才能有地摆放。

`内存分段指的是处理器为 访问内存而采用的机制，称之为内存分段机制，程序分段是软件中人为逻辑划分的内存区域，它本身也是 内存，所以处理器在访问该区域时，也会采用内存分段机制，用段寄存器指向该区域的起始地址。`

## 物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别

物理地址就是物理内存真正的地址，相当于内存中每个存储单元的门牌号，具有唯一性。不管在什么模式下， 不管什么虚拟地址、线性地址，CPU 最终都要以物理地址去访问内存，只有物理地址才是内存访问的终点站。 在实模式下，“段基址+段内偏移地址”经过段部件的处理，直接输出的就是物理地址，CPU 可以直 接用此地址访问内存。 而在保护模式下，“段基址+段内偏移地址”称为线性地址，不过，此时的段基址已经不再是真正的地址 了，而是一个称为选择子的东西。它本质是个索引，类似于数组下标，通过这个索引便能在 GDT 中找到相应 的段描述符，在该描述符中记录了该段的起始、大小等信息，这样便得到了段基址。若没有开启地址分页功能， 此线性地址就被当作物理地址来用，可直接访问内存。若开启了分页功能，此线性地址又多了一个名字，就是 虚拟地址（虚拟地址、线性地址在分页机制下都是一回事）。虚拟地址要经过 CPU 页部件转换成具体的物理地 址，这样 CPU 才能将其送上地址总线去访问内存。 无论在实模式或是保护模式下，段内偏移地址又称为有效地址，也称为逻辑地址，这是程序员可 见的地址。这是因为，最终的地址是由段基址和段内偏移地址组合而成的。由于段基址已经有默认的 啦，要么是在实模式下的默认段寄存器中，要么是在保护模式下的默认段选择子寄存器指向的段描述 符中，所以只要给出段内偏移地址就行了，这个地址虽然只是段内偏移，但加上默认的段基址，依然 足够有效。 线性地址或称为虚拟地址，这都不是真实的内存地址。它们都用来描述程序或任务的地址空间。由于 分页功能是需要在保护模式下开启的，32 位系统保护模式下的寻址空间是 4GB，所以虚拟地址或线性地 址就是 0～4GB 的范围。转换过程如图

![image-20210222234819600](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222234819600.png)

## 什么是段重叠

> 依然假设在实模式下（并不是说在保护模式下就不存在段重叠，只是这样就会少解释了相关数据结构， 如段描述符，不过这不重要，原理是一样的），一个段最大为 64KB，其大小由段内偏移地址寻址范围决定， 也就是 2 的 16 次方。其起始位置由段基地址决定。CPU 的内存寻址方式是：给我一个段基址，再给我一 个相对于该段起始位置的偏移地址，我就能访问到相应内存。 它并不要求一个内存地址只隶属于某一个段，所以在上面的 图 0-2 中，欲访问内存 0xC03，段基址可以选择 0xC00，0xC01， 0xC02，0xC03，只不过是段内偏移量要根据段基地址来调整 罢了。用这种“段基地址：段内偏移”的组合，0xC00：3 和 0xC02：1 是等价的，它们都访问到同一个物理内存块。但段 的大小决定于段内偏移地址寻址范围，假设段 A 的段基址是 从 0xC00 开始，段 B 的段基址是从 0xC02 开始，在 16 位宽 度的寻址范围内，这两个段都能访问到 0xC05 这块内存。用 段 A 去访问，其偏移为 5，用段 B 去访问，其偏移量为 3。 这样一来，用段 B 和段 A 在地址 0xC02 之后，一直到段 B 偏移地址为 0xfffe 的部分，像是重叠在一起了，这就是段重 叠了，如图

![image-20210222234910886](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222234910886.png)

## 什么是平坦模型

> 平坦模型是相对于多段模型来说的，所以说平坦模型指的就是一个段。比如在实模式下，访问超过 64KB 的内存，需要重新指定不同的段基址，通过这种迂回变通的方式才能达到目的。在保护模式下， 由于其是 32 位的，寻址范围便能够达到 4GB，段内偏移地址也是地址，所以也是 32 位。可见，在 32 位环境下用一个段就能够访问到硬件所支持的所有内存。也就是说，段的大小可以是地址总线能够到达 的范围。既然平坦模型是相对于多段模型来说的，为什么不称为单段模型，而称为平坦呢，我估计很多 读者已经明白了，用多个小段再加上不断换段基址的方式访问内存确实够麻烦的，可能换着换着就晕了， 别忘记了，这种多段模型为了访问到 1MB 地址空间，还需要额外打开 A20 地址线呢，这种访存方式本 身就是种补救措施，相当于给硬件打了个补丁，既然是补丁，访问内存的过程必然是不顺畅的。相对于 那么麻烦的多段模型，平坦模型不需要额外打开 A20 地址线，不需要来回切换段基址就可以在地址空间 内任意翱翔。如果把内存段比喻成小格子的话，平坦模型下的内存访问，没有众多小格子成为羁绊，可 谓一路“平坦”。 所以“平坦”这两个字，突显了当时的程序员受多段模型折磨之苦，迫不及待地想表达其优势的喜 悦之情。

## cs、ds 这类 sreg 段寄存器，位宽是多少

CPU 中存在段寄存器是因为其内存是分段访问的，这是设计之初决定的，属于基因里的东西。前面 已经介绍过了内存分段访问的方法，这里不再赘述。 CPU 内部的段寄存器（Segment reg）如下。 

（1）CS—代码段寄存器（Code Segment Register），其值为代码段的段基值。

（2）DS—数据段寄存器（Data Segment Register），其值为数据段的段基值。 

（3）ES—附加段寄存器（Extra Segment Register），其值为附加数据段的段基值，称为“附加”是 因为此段寄存器用途不像其他 sreg 那样固定，可以额外做他用。 

（4）FS—附加段寄存器（Extra Segment Register），其值为附加数据段的段基值，同上，用途不固定， 使用上灵活机动。 

（5）GS—附加段寄存器（Extra Segment Register），其值为附加数据段的段基值。 

（6）SS—堆栈段寄存器（Stack Segment Register），其值为堆栈段的段值。 32 位 CPU 有两种不同的工作模式：实模式和保护模式。 

> 每种模式下，段寄存器中值的意义是不同的，但不管其为何值，在段寄存器中所表达的都是指向的段 在哪里。在实模式下，CS、DS、ES、SS 中的值为段基址，是具体的物理地址，内存单元的逻辑地址仍为 “段基值：段内偏移量”的形式。在保护模式下，装入段寄存器的不再是段地址，而是“段选择子”（Selector）， 当然，选择子也是数值，其依然为 16 位宽度。 可见，在 32 位 CPU 中，sreg 无论是工作在 16 位的实模式，还是 32 位的保护模式，用的段寄存器都 是同一组，并且在 32 位下的段选择子是 16 位宽度，排除了段寄存器在 32 位环境下是 32 位宽的可能，综 上所述，sreg 都是 16 位宽。

## 为什么 Linux 系统下的应用程序不能在 Windows 系统下运行

其实，Windows 下的程序也无法直接在 Linux 下运行。 对于这个问题，很多同学都会马上给出答案：格式不同。其实……答对啦，确实是格式不同，不过这只 是一方面，还有另一方面，系统 API 不同，API 即 Application Programming Interface，应用程序编程接口。 先说说格式。其实格式也算是协议，就是在某个固定的位置有固定意义的数据。Linux 下的可执行程序格式 是 elf，也就是 “Executable and Linking Format”平时咱们用 readelf 命令可以查看 elf 文件头，里面有节（section） 信息、段（segment）信息、程序入口（entry_point）、哪个段由哪些节组成等信息。 而 Windows 下的可执行程序是 PE 格式（portable executable，可移植的可执行文件），因为我没了解 过，所以具体文件头咱们就不关注了，有兴趣的同学自行查看。 那如果 Linux 支持了 PE 格式就可以运行 Wndows 程序了吗？也不行，因为在上面说过了，还有系统 API 不同。Linux 中的 API 称为系统调用，是通过 int 0x80 这个软中断实现的。而 Windows 中的 API 是存 放在动态链接库文件中的，也就是 Windows 开发人员常说的 DLL，即 Dynamic Link Library 的缩写。LL 是 一个库，里面包含代码和数据，可供用户程序调用，DLL 不是可执行文件，不能够单独运行。也就是说， Linux 中的可执行程序获得系统资源的方法和 Windows 不一样，所以显然是不能在 Windows 中运行的。 除以上原因外，这还和编译器、标准库有关，不再列举。

## 局部变量和函数参数为什么要放在栈中

> 局部变量，顾名思义其作用域属于局部，并不是像 static 那样属于全局性的。全局的变量，意味着谁 都可以随时随地访问，所以其放在数据段中。而局部变量只是自己在用，放在数据段中纯属浪费空间，没有必 要，故将其放在自己的栈中，随时可以清理，真正体现了局部的意义。这个就是堆栈框架，提到了就说一点吧， 栈由于是向下生长的，堆栈框架就是把 esp 指针提前加一个数，原 esp 指针到新 esp 指针之间的栈空间用来存 储局部变量。解释一个概念，堆是程序运行过程中用于动态内存分配的内存空间，是操作系统为每个用户进程 规划的，属于软件范畴。栈是处理器运行必备的内存空间，是硬件必需的，但又是由软件（操作系统）提供的。

> 堆是堆，而堆栈就是栈，和堆没关系，只是都这么叫。栈和堆栈都是指的栈，在 C 程序的内存布局中，由于 堆和栈的地址空间是接壤的，栈从高地址往低地址发展，堆是从低地址往高地址发展，堆和栈早晚会碰头，它 们各自的大小取决于实际的使用情况，界限并不明朗，所以这可能是堆栈常放在一直称呼的原因吧。 函数参数为什么会放到栈区呢？第一也是其局部性导致的，只有这个函数用这个参数，何必将其放在 数据段呢。第二，这是因为函数是在程序执行过程中调用的，属于动态的调用，编译时无法预测会何时调 用及被调用的次数，函数的参数及返回值都需要内存来存储，如果是递归调用的话，参数及返回值需要的 内存空间也就不确定了，这取决于递归的次数。也许这么说您也依然觉得费解，如果完全明白，需要了解 一下编译原理，很多知识都是通过实践后才搞明白的。当然我不是说让您为了搞明白这个问题而去尝试写 个编译器。 总之，在函数的编译阶段根本无法确定它会被调用几次，其参数和函数的返回地址也要内存来存储， 所以也不知道其会需要多少内存。我想，即使神通广大的编译器设计者可以预测这些了，那提前准备好内 存也是一种浪费，而且您想啊，在系统中可用内存紧缺的情况下，提前把内存分配给目前并不使用内存的 进程（只因为要存储其函数参数），而眼前需要内存的程序若无内存可用，引用罗永浩老师的一句话：“我 想不到比这个更伤感的事情了”所以编译器为了让世界更美好一些，选择将为函数参数动态分配内存，也 就是在每次调用函数时才为它在栈中分配内存。

## 为什么说汇编语言比 C 语言快

> 首先说这是谬论（有没有想喷我的冲动？大人且慢，请听我慢慢道来）。 不管用什么语言，程序最终都是给 CPU 运行的，只有 CPU 才能让程序跑起来。CPU 不知道什么是汇 编语言、C 语言，甚至 Java、PHP、Python 等，它根本不知道交给它的指令曾经经历过那么多的解释、编 译工序。不管什么语言，编译器最终翻译出来的都是机器指令。所以在这一点来说，汇编语言编译器编译 出来的机器指令和 C 编译器编译出来的机器指令无异。 那为什么还说汇编语言更快呢？ 我觉得应该说汇编语言生成的指令数更少，从而“显得”执行得快，并不是汇编语言本身有多少威 武霸气，而是因为汇编语言本身就是机器指令的符号化，意思是说，一个汇编语言中的符号对应一个机 器指令，它们是一一对应的。用汇编语言写程序就相当于直接在写机器指令，汇编语言编译器并不会添 加额外的语句，因此汇编语言写的程序会更直接，CPU 不会因多执行一些无关的指令而浪费时间，当然 会快。 再看看 C 编译器为咱们做了什么。为了让 C 程序员更加方便地编程，C 编译器在背后做了大量的工 作，不仅如此，出于通用性、易用性或者其他方面的考虑，C 编译器往往会在背后加入额外的 C 语言代码 来支撑，因此实际的 C 代码量就变得很大。另外在编译阶段，C 代码会率先被编译成汇编代码，然后再由 汇编器将汇编代码翻译成机器指令，由于 C 代码已经变得冗余了，编译出的汇编代码自然也会冗余，其 机器指令也会多很多。 大多数人愿意用 C 语言写程序是因为 C 语言强大且更容易掌握。但这份优势是有代价的。C 程序员 不用考虑切换栈，不用考虑用哪个段。这些必须要考虑的事情，程序员不考虑，只好由编译器帮着考虑了。 而且为了通用性、功能，甚至安全方面的考虑，自然在背后要多写一些代码。就拿打印字符串来说，C 语 言的 printf()，这里面的工作可多了去了，不仅要检查打印的数据类型，还要负责格式，小数点保留位数…… 而在汇编语言中只要往显存地址处 mov 一个字符就行了，字符串也就是多几个 mov 操作而已。您说，C 语 言为了让开发者用得爽，自己在背后做了多少贡献。 总结：高级语言如 C 语言为了通用性等，需要兼顾的东西比较多，往往还加入了一些额外的代码， 因此编译出来的汇编代码比较多，很多部分都是一些周边功能，并不是直接起作用的，不如用汇编语言直接 写功能相关的部分效果来得更直接，C 语言被编译成机器指令后，生成的机器指令当然也包括这些额外的部分， 相当于多执行了一些“看似没用”的指令，因此会比直接用汇编语言慢。

## 编译型程序与解释型程序的区别

解释型语言，也称为脚本语言，如 JavaScript、Python、Perl、PHP、Shell 脚本等。它们本身是文本文 件，是某个应用程序的输入，这个应用程序是脚本解释器。 由于只是文本，这些脚本中的代码在脚本解释器看来和字符串无异。也就是说，脚本中的代码从来没真 正上过 CPU 去执行，CPU 的 cs：ip 寄存器从来没指向过它们，在 CPU 眼里只看得到脚本解释器，而这些 脚本中的代码，CPU 从来就不知道有它们的存在。这些脚本代码看似在按照开发人员的逻辑执行，本质上 是脚本解释器在时时分析这个脚本，动态根据关键字和语法来做出相应的行为。因此脚本中若出现错误，先 前正确的部分也会被正常执行，这和编译型程序有很大区别。 顺便猜想一下解释型语言是如何执行的。我们在执行一个 PHP 脚本时，其实就是启动一个 C 语言编 写出来的解释器而已，这个解释器就是一个进程，和一般的进程是没有区别的，只是这个进程的输入则是 这个 php 脚本，在 php 解释器中，这个脚本就是个长一些的字符串，根本不是什么指令代码之类。只是这 种解释器了解这种语法，按照语法规则来输出罢了。 举个例子，假设下面是文件名为 a.php 的 PHP 代码。

```
<?php 这是 php 语法中的固定开始标签
 echo "abcd"； 输出字符串 abcd
?> 固定结束标签
```

PHP 解释器分析文本文件 a.php 时，发现里面的 echo 关键字，将其后面的参数获取后就调用 C 语言中提供 的输出函数，如 printf（（echo 的参数））。PHP 解释器对于 PHP 脚本，就相当于浏览器对于 JavaScript 一样，不 过这个可完全是我猜测的，我不知道 PHP 解释器里面的具体工作，以上为了说清楚我的想法，请大家辩证地看。 而编译型语言编译出来的程序，运行时本身就是一个进程。它是由操作系统直接调用的。也就是由操作系 统加载到内存后，操作系统将 CS：IP 寄存器指向这个程序的入口，使它直接上 CPU 运行。总之调度器在就 绪队列中能看到此进程。而解释型程序是无法让调度器“入眼”的，调度器只会看到该脚本语言的解释器。

## 什么是大端字节序、小端字节序

内存是以字节为单位读写的，其最小的读写单位就是字节。故如果在内存中只写入一个字节，一个内 存的存储单元便可将其容纳了，只要访问这一内存地址就能够完整取出这 1 字节。可是 1 字节要能够表示的 范围只有 0～255（先只考虑无符号数），超过这个范围的数，只好用多个字节连在一起来表示。因此，在我 们的 32 位程序中，定义的数据类型很多。1 字节的数据类型只有 char 型，像 int 型要占 4 字节，double 型要 占用 8 字节。正如解决了一个问题又抛出了新的问题一样，解决了数值范围的问题，那带来的新的问题是这 么多个字节该以怎样的顺序排放呢。一个超过 255 的数字必然要占用 2 个字节以上，这两个字节，在物理内 存中，哪个在前？哪个在后？拿 0x1234 举例，数值中的高位 12 是放在内存的高地址处，还是低地址处？ 于是就产生了这两种相反的排列顺序。 （1）小端字节序是数值的低字节放在内存的低地址处，数值的高字节放在内存的高地址。 （2）大端字节序是数值的低字节放在内存的高地址处，数值的高字节放在内存的低地址。 为了让大家理解得更直观，我在虚拟机 bochs 中操作一下，咱们看一下真正的 0x12345678 在内存中 是怎样存储的，如图 0-9 所示。 上面的 b 0x7c00 是我在内存的 0x7c00 处插入了一个断点，其实这与要说明的问题无关，怕有同学好 奇就稍带说一句，因为 0x7c00 是 BIOS 把 mbr 加载到内存后会跳转过去的地址，所以在此处能停下来。 咱们只要关注 xp/4 0x200000，这是显示以物理内存 0x200000 开始处的 4 个字节，可见其为 00、00、00、 00，地址是从左到右逐渐升高的，其中每一对 00 就占用 1 个字节，它们的值都是 0。现在用 setpmem 命令 在该地址处写入 0x12345678 后，再用 xp/4 命令查看内存地址 0x200000 处的内容，可见已经不是 4 个 00 了， 由内存的低地址到高地址，依次变成了 0x78、0x56、0x34、0x12。这说明 bochs 模拟的 x86 体系结构虚拟 机是小端字节序，即数值上的低字节 0x78 在物理内存上的低地址，其他数值也依次符合小端字节序。 选择哪种字节序，这是硬件厂商考虑的问题，对于这种二选一的选择，选择了一方的时候，就必然丢 了另一方。 看看这两种字节序的优势。 （1）小端：因为低位在低字节，强制转换数据型时不需要再调整字节了。 （2）大端：有符号数，其字节最高位不仅表示数值本身，还起到了符号的作用。符号位固定为第一字 节，也就是最高位占据最低地址，符号直接可以取出来，容易判断正负。 简要说明一下小端的优势。因为在做强制数据类型转换时，如果转换是由低精度转向高精度，这数值 本身没什么变化，如 short 是 2 字节，将其转换为 4 字节的 int 类型，无非是由 0x1234 变成了 0x00001234， 数值上是不变的，只是存储形式上变了。如果转换是高精度转向低精度，也就是多个字节的数值要减少一 些存储字节，这必然是要丢弃一部分数值。编译器的转换原则是强制转换到低精度类型，丢弃数值的高字 节位，只保留数值的低字节，如图

![image-20210222235457553](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222235457553.png)

由图 0-10 上输出可见，0x12345678 由 4 字节的 int 型强制转向了 2 字节的 short 型后，只保留了低字 节的 0x5678。 对于大端的优势，就硬件而言，就是符号位的判断变得方便了。最高位在最低地址，也就是直接就可以 取到了，不用再跨越几个字节，减少了时钟周期。另外，对于人类来说，还是大端看上去顺眼，毕竟咱们存 储 0x12345678 到内存时，它在内存中的存储顺序也是 0x12345678，而不是 0x78563412，这样看上去才直观。 常见 CPU 的字节序如下。

（1）大端字节序：IBM、Sun、PowerPC。 （2）小端字节序：x86、DEC。 ARM 体系的 CPU 则大小端字节序通吃，具体用哪类字节序由硬件选择。 字节序不仅是在 CPU 访问内存中的概念，而且也包括在文件存储和网络传输中。bmp 格式的图片就 属于小端字节序，而 jpeg 格式的图片则为大端字节序，这没什么可说的，采用什么序列完全是开发者设 计产品时的需要。 网络字节序就是大端字节序，所以在 x86 架构上的程序在发送网络数据时，要转换字节顺序。 关于字节序就介绍到这里，读者若觉得意犹未尽可以自行查阅。

## BIOS 中断、DOS 中断、Linux 中断的区别

在计算机系统中，无论是在实模式，还是在保护模式，在任何情况下都会有来自外部或内部的事件发生。 如果事件来自于 CPU 内部就称为异常，即 Exception。例如，CPU 在计算算法时，发现分母为 0，就抛出了除 0 异常。如果事件来自于外部，也就是该事件由外部设备发出并通知了 CPU，这个事件就称为异常。 BIOS 和 DOS 都是存在于实模式下的程序，由它们建立的中断调用都是建立在中断向量表（Interrupt Vector Table，IVT）中的。它们都是通过软中断指令 int 中断号来调用的。 中断向量表中的每个中断向量大小是 4 字节。这 4 字节描述了一个中断处理例程（程序）的段基址和 段内偏移地址。因为中断向量表的长度为 1024 字节，故该表最多容纳 256 个中断向量处理程序。计算机 启动之初，中断向量表中的中断例程是由 BIOS 建立的，它从物理内存地址 0x0000 处初始化并在中断向 量表中添加各种处理例程。 BIOS 中断调用的主要功能是提供了硬件访问的方法，该方法使对硬件的操作变得简单易行。这句话 是否也表明了不通过 BIOS 调用也是可以访问硬件的？必须是的，否则 BIOS 中断处理程序又是如何操作 硬件呢？操作硬件无非是通过 in/out 指令来读写外设的端口，BIOS 中断程序处理是用来操作硬件的，故 该处理程序中一定到处都是 in/out 指令。 BIOS 为什么添加中断处理例程呢？ （1）给自己用，因为 BIOS 也是一段程序，是程序就很可能要重复性地执行某段代码，它直接将其写 成中断函数，直接调用多省心。 （2）给后来的程序用，如加载器或 boot loader。它们在调用硬件资源时就不需要自己重写代码了。 BIOS 是如何设置中断处理程序的呢？ BIOS 也要调用别人的函数例程。 BIOS 够底层吧？难道它还要依赖别人？是啊，BIOS 也是软件，也要有求于别人。首先硬件厂商为了 让自己生产的产品易用，肯定事先写好了一组调用接口，必然是越简单越好，直接给接口函数传一个参数， 硬件就能返回一个输出，如果不易用的话，厂商肯定倒闭了。 那这些硬件自己的接口代码在哪里呢？ 每个外设，包括显卡、键盘、各种控制器等，都有自己的内存（主板也有自己的内存，BIOS 就存放 在里面），不过这种内存都是只读存储器 ROM。硬件自己的功能调用例程及初始化代码就存放在这 ROM 中。根据规范，第 1 个内存单元的内容是 0x55，第 2 个存储单元是 0xAA，第 3 个存储单位是该 rom 中以 512 字节为单位的代码长度。从第 4 个存储单元起就是实际代码了，直到第 3 个存储单元所示的长度为止。 有问题了，CPU 如何访问到外设的 ROM 呢？ 访问外设有两种方式。 （1）内存映射：通过地址总线将外设自己的内存映射到某个内存区域（并不是映射到主板上插的内存条中）。 （2）端口操作：外设都有自己的控制器，控制器上有寄存器，这些寄存器就是所谓的端口，通过 in/out 指令读写端口来访问硬件的内存。 控制显卡用的便是内存映射+端口操作的方式。从内存的物理地址 0xA0000 开始到 0xFFFFF 这部分内存中，一部分是专门用来做映射的，如果硬件 存在，硬件自己的 ROM 会被映射到这片内存中的某处，至于如何映射过去的，咱们暂时先不要深入了， 这是硬件完成的工作。 如图 0-11 所示，BIOS 在运行期间会扫描 0xC0000 到 0xE0000 之间的内存，若在某个区域发现前两个字 节是 0x55 和 0xAA 时，这意味着该区域对应的 rom 中有代码存在，再对该区域做累加和检查，若结果与第 3 个字节的值相符，说明代码无误，就从第 4 个字节进入。这时开始执行了硬件自带的例程以初始化硬件自身， 最后，BIOS 填写中断向量表中相关项，使它们指向硬件自带的例程。

![image-20210222235628230](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222235628230.png)

中断向量表中第 0H～1FH 项是 BIOS 中断。 有没有新的疑问？外设的内存是如何被映射的？我也不知道，这是早期硬件工程师们大胆且天才的做 法，他们在很久以前就解决了。有知道的同学希望你告诉我，哈哈，在这里，我就先当它是我的公设了。 另外，上面说的是 BIOS 在填写中断向量表，那该表是谁创建的呢？答案就是 CPU 原生支持的，不用谁负 责创建。之前我曾说过，软件是靠硬件来运行的，软件能实现什么功能，很大程度上取决于硬件提供了哪些支持。 软件中只要执行 int 中断向量号，CPU 便会把向量号当作下标，去中断向量表中定位中断处理程序并执行。 如果哪位同学想查看下 BIOS 在中断向量表 IVT 中建立了哪些中断例程，可以在虚拟机 bochs 或 qume 中查看，我在这里贴个表，即表 0-2，大家可以先了解下。

![image-20210222235854059](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210222235854059.png)

## 什么是魔数

魔数，magic number，这让一部分人感觉到迷惑，也让另一部分人迷惑。哈哈，两个迷惑，把我们都 搞迷惑了，作者你到底想表达什么意思啊。没错，其实魔数的本意就是让人感到迷惑的数，看到某个数， 不知道其代表何意，用东北话说，都蒙圈了。一部分人对这个概念迷惑的原因是这有什么好解释的，一种 司空见惯的东西，即使不知道是怎么来的，但由于大脑经常被其训练，对其已经形成深刻的印象，似乎理 所当然地接受了。当我向别人请教一个类似的问题时，如果被回复“这是规定”时，我就很无语。任何规 定都是出自于某种原因才做出的，很少有规定是靠拍脑门或抓阄决定的。就像国外的电视剧，一部称为一 季，季是由 season 翻译过来的，表示季节，一个时段。一个季节过去了，这和电视剧整体情节暂告一段 落是一样的，这较容易理解。 另一部分人感到迷惑的原因是真心想搞清楚概念是什么意思，我也属于这一类。 魔数，其实也称为神奇数字，我们大多数人是在学习计算机过程中接触到这个词的。它被用来为重要 的数据定义标签，用独特的数字唯一地标识该数据，这种独特的数字是只有少数人才能掌握其奥秘的“神 秘力量。” 对魔数简单的阐述就是：不明就理地出现一个数字，不知道其是什么意思，感觉看不透，猜不出，就 像魔法一样很神秘。了解一定上下文的人肯定知道是什么意思，一般局外人绞尽脑汁也不解其意。就像小 姑娘对着小伙子伸出大拇指和食指，小伙子马上就意会了，这是让我晚上 8 点在村口东边老槐树下见。 如果程序中出现这样的代码： 
```
int a = 2014 – 1987；
```
 根据直觉，似乎这是在求年龄，因为 2014 是和现在很接近的年份，而 1987 似乎是生日。但这只是主 观估计，万一这两个数字表示的是这个月和上个月的电表计数呢，人家在查电费不行吗……修改一下代码。

```
 #define birthday 1987； 
int a = 2014 – birthday；
```

 由于 1987 用了一个宏代替，即使变量名称不改为 age，还叫作 a，大家也明确了这是在求年纪呢。 故，直接出现的一个数字，只要其意义不明确，感觉很诡异，就称之为魔数。魔数应用的地方太多了， 如 elf 文件头。 
```
ELF Header： Magic： 7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00 
```
这个 Magic 后面的一长串就是魔数，elf 解析器（通常是程序加载器）用它来校验文件的类型是否是 elf。 主引导记录最后的两个字节的内容是 0x55，0xaa，这表明这个扇区里面有可加载的程序，BIOS 就用 它来校验该扇区是否可引导。 有人说只要为这些数字赋予实际的意义不就行了吗。其实，无论怎么给这组陌生的数字赋予名称，它 都不像熟悉的出生日期那样直观易懂（如对于 19590318，不解释大家也会知道 0318 是 3 月 18 日），反而 还要额外增加一些内容来解释，得不偿失，所以这就是魔数不得不存在的原因。 可见，计算机中处处是协议、约定。不过为了程序意义清晰可维护性强，尽量还是少用魔数。

## 操作系统是如何识别文件系统的

我们知道，一个硬盘上可以有很多分区，每个分区的格式又可以不同。就拿 Linux 来说，既能识别 ext3， 又能识别 ext4。可能有同学会说，这两个分区的文件系统都是 Linux 自己专用的，当然认得自己的东西了。 可是自己的东西也得有个辨别的地方，否则凭什么说“认得”呢。 其实这是之前介绍过的魔数的作用，文件系统也有自己的魔数，魔数的神秘力量在此施展了。各分区 都有超级块，一般位于本分区的第 2 个扇区，比如若各分区的扇区以 0 开始索引，其第 1 个扇区便是超级 块的起始扇区。超级块里面记录了此分区的信息，其中就有文件系统的魔数，一种文件系统对应一个魔数， 比对此值便知道文件系统类型了

## 如何控制 CPU 的下一条指令

> 其实此问题我一直犹豫要不要写出来，因为大部人都觉得这个问题有些匪夷所思，CPU 是负责执行指令的， 它会按照程序的执行流程走，此问题的目的其实就是想知道如何牵着 CPU 的鼻子走。当初我被问这个问题时也 觉得很诧异，甚至我觉得自己可能没理解人家的意思。后来他这样跟我说：“CPU 要执行的下一条指令是在 CS： IP 寄存器吧?”我说：“是啊”。他又问：“CS 和 IP 寄存器，是用 mov 指令修改的吗？”我听后，顿时觉得他这 个问题很有意义，暗自对他有些小敬佩，我相信很多人都没想过，CS 和 IP 能不能用 mov 指令去修改。 是这样的，我们常说的用于存放下一条指令地址的寄存器称为程序计数器 PC（Program Counter）。这 个名词在我看来是个概念级别的内容，它只是 CPU 中有关下一条指令存放地址的统称，也就是说 PC 是 用来表示下一条指令的存放地址，具体的实现形式不限，后面会有所讨论。 CPU 按照指令集可以分为很多种，由于 PC 只是个概念，所以在不同种类的 CPU 中，有不同的实现。 注意啦，这里的“不同种类”不是指 CPU 品牌，而是指 CPU 体系结构，如 INTEL 和 AMD 同属 x86 构架， 如果您对此不了解，细心的我早已在下面为您准备好了体系结构、指令集的相关内容。由于此方面内容较 独立，我专门将其组织成一个小节供大伙儿参考，如果您现在感兴趣，可以先参阅“指令集、体系结构、 微架构、编程语言”这一节。 在 x86 体系结构的 CPU 中，也就是咱们大多数人使用的 INTEL 或 AMD 公司出品的桌面处理器，程 序计数器 PC 并不是单一的某种寄存器，它是一种寄存器组合，指的段寄存器 CS 和指令指令寄存器 IP。 CS 和 IP 是 CPU 待执行的下一条指令的段基址和段内偏移地址，不能直接用 mov 指令去改变它们， 我想可能的一个原因是：mov 指令一次只能改变一个寄存器，不能同时将 cs 和 ip 都改变。如果只改变了 其中一个会引起错误。如改变了 cs 的值后，ip 的值还是原先 cs 段的偏移，很难保证新的 cs 段内的偏移地 址 ip 处的指令是正确的。因此，有专门改变执行流的指令，如 jmp、call、int、ret，这些指令可以同时修 改 cs 和 ip，它们在硬件级别上实现了原子操作。 以上说的是x86体系的CPU，其他类型的CPU是怎样的呢？这就取决于具体实现啦，咱们这里拿ARM 举例，它的程序计数器有个专门的寄存器，名字就叫 PC，想要改变程序流程，直接对该寄存器赋值便可。 与 x86 不同的是在 ARM 中可以用 mov 指令来修改程序流，在 ARM 体系 CPU 的汇编器中，寄存器 的名称在汇编语言中是以“r 数字”的形式命名的，例如汇编代码：mov pc，r0，表示将寄存器 r0 中的内 容赋值给程序寄存器 PC，这样就直接改变了程序的执行流。 总结一下，程序计数器 PC 负责处理器的执行方向，它只是获取下一条指令的方法形式，在不同体系 结构的 CPU 中有不同的实现方法。

## 库函数是用户进程与内核的桥梁

crt 是什么？CRT，即 C Run-Time library，是 C 运行时库。 什么是运行时库？ 运行时库是程序在运行时所需要的库，该库是由众多可复用的函数文件组成的，由编译器提供。 所以，C 运行时库，就是 C 程序运行时所需要的库文件，在我们的环境中，它由 gcc 提供。 大家这下应该明白了，我们在程序中简单地一句 include <标准头文件>之所以有效，是因为编译器提供 的 C 运行库中已经为我们准备好了这些标准函数的函数体所在的目标文件，在链接时默默帮我们链接上了。 顺便说一句，这些目标文件都是待重定位文件，重定位文件意思是文件中的函数是没有地址的，用 file 命 令查看它们时会显示 relocatable，它们中的地址是在与用户程序的目标文件链接成一个可执行文件时由链接器 统一分配的。所以 C 运行时库中同样的函数与不同的用户程序链接时，其生成的可执行文件中分配给库函数 的地址都可能是不同的。每一个用户程序都需要与它们链接合并成一个可执行文件，所以每一个可执行文件中 都有这些库文件的副本，这些库文件相当于被复制到每个用户程序中。所以您清楚了，即使咱们的代码只有十 几个字符，最终生成的文件也要几 KB，就是这个道理。 还有一点内容要解释，前面说过用户程序要使用系统调用才能使用操作系统的功能，我们的 func_inc.d 中，也用到了 printf 函数，照我这么说的话，打印字符是内核的功能，那么生成的 main.bin 文件在执行 printf 函数时，内部一定会执行系统调用？没错！我们来验证一下。 我们可以用 ltrace 命令跟踪一下程序 main.bin 的执行过程就好啦。ltrace 命令用来跟踪程序运行时调 用的库函数，我们的 printf 函数绝对是个标准的库函数，让我们先尝尝鲜，看看不加参数执行时的输出是 否是我们想要的。

## 转义字符与 ASCII 码

计算机世界中是以二进制来运行的，无论是指令、数据，都是以二进制的形式提交给硬件处理的，字 符也一样，必须转换成二进制才能被计算机识别。所以各种各样的字符编码产生，简单来说，字符编码就是用 唯一的一个二进制串表示唯一的一个字符。其中最著名的字符编码就是 ASCII 码。 ASCII 码表中字符按可见分成两大类，一类是不可见字符，共 33 个，它们的 ASCII 码值是 0～31 和 127，属于控制字符或通信专用字符。表中其余的字符是可见字符，它们的 ASCII 码值是 32～126，属于 数字、字母、各种符号。 对于计算机来说，任何字符都是用 ASCII 码表示的，人要是与计算机交流，虽然可以直接输入字符的 ASCII 码，但这太不人道了，计算机的发明是为了给人解决问题而并非制造问题。人习惯用所见即所得的 方式使用字符，我要输入字符 a 的时候，直接按下键盘上的 a 键就行了，不要让我输入其 ASCII 码 0x61。 这要求是合理的，我们在键盘上键入的每个按键，都会由输入系统根据 ASCII 码表转换成对应的二进制 ACSII 码形式。这对普通用户来说够用了，他们很少写程序，可是作为程序员，我们经常要输出字符串， 字符串中的可见字符直接从键盘敲入就行了，对于那些不可见字符，如回车换行符等，肯定不能用键盘在 字符串中直接敲下一个回车键。

我们的问题是不可见字符如何写出来，也就是说我们在写字符串时，如何在其中加入不可见的控制符， 这就需要编译器或解释器的支持了。 由于可见字符本身是看得见的，所见即所得，大家在使用中并不会有陌生感。对于那些不可见的控制 字符，如果想使用它们时，该怎样表示它们呢？比如我就是要让程序输出一段话，在结束处换行。控制字 符看不见摸不着，怎么写出来？所以在使用这些不可见字符时必须想办法让其可见，但又不能表示成其他 可见字符，所以，只能让可见字符不表示自身了，哈哈，有点难是吗？这么艰巨的任务显然只用一个可见 字符是不可能完成的，于是编译器想出了一个办法，它引用了另一个可见字符'\'来搭配其他可见字符，用 这种可见字符组合的形式表达不可见字符。表面上看，字符'\'是让其他可见字符的意义变了，所以称'\'为 转义字符，但本质上，这两个可见字符合起来才是完整的不可见字符，比如换行符'\n'，'\'和'n'放到一起才 是换行符的意义，并不是因为'n'前面有个'\'，'n'就不再是'n'，而是换行符，一定要清楚不是这样的。 ASCII 码表中任何字符都是 1 个字节大小，在字符串中不可见字符虽然用“转义字符+可见字符”两个字 符来表示，但这只是编译器为了让人们能写出不可见字符的方式，目的是让不可见字符变得“可见”，针对的 是人，这样人们写程序时就能在字符串中用到不可见字符。不可见字符本身在编译后还是那 1 个字节的 ASCII 码。说白了，我们能够将不可见字符显示出来，原因就是编译器在给我们做支持，它将“转义字符+可见字符” 这种形式的不可见字符转换成了该不可见字符的 ASCII 码。 为了说清楚，咱们以编译器为界限，在编译器左边的是人，这里的字符串是供人使用的，转义字符是 存在于这一边的。编译器右边的是机器，这里的字符串使用的都是 ASCII 码。



在编译器左边： 

char* ptr=”abc\n”； 

此部分对应的内容是 0x61 0x62 0x63 0x5c 0x6e。

 编译器右边： “abc\n”

对应的内容是 0x61 0x62 0x63 0xa



编译器的左边和右边是不一样的，区别是对“\n”的处理。编译器左边把它当成了两个字符，编译器 右边把它当成了一个字符。想想也是，毕竟代码只是文本字符串，字符串”abc\n”中的'\'和'n'肯定是两个 字符，编译器会把'\'和'n'组合到一起成为'\n'而解释成回车换行。可能您还是觉得怀疑，那我说一下编译器 对字符串的解释过程。 编译器对字符串的处理一般是逐个字符处理的，这样便于处理转义字符。若发现字符为'\'，就意识到 这是转义字符，按常理说后面肯定要跟着另一可见字符，于是先不做任何处理，马上把后面的字符读进来， 分析这两个字符的组合是哪个控制字符后一并处理。 咱们这里拿编译器解释字符串”abc\n”举例。 代码中的'\n'本身由两个字符'\'和'n'组成，'\n'是给人看的，用于在字符串中使用，其 ASCII 码是 0xa， 是给机器看的。在计算机中，所有的字符都已经成了 ASCII 码，字符串”abc\n”则变成了 ASCII 码：0x61 0x62 0x63 0x5c 0x6e。 编译器要逐个对比字符串中每个字符，前几个字符是'a'、'b'、'c'，这都是可见字符，没有异议，直接处理。 当发现字符是'\'，知道这是转义字符，得知道'\'后面的字符是什么才能确定是哪个不可见字符，于是暂停处理'\'， 把后面的字符读进来，发现是'n'，便知道这是'\n'，表示一个换行符，于是将'\'和'n'用换行符的 ASCII 代替，原来 字符串”abc\n”的 ASCII 码就变成了 0x61 0x62 0x63 0xa。

## MBR、EBR、DBR 和 OBR 各是什么

这几个概念主要是围绕计算机系统的控制权交接展开的，整个交接过程就是个接力赛，咱们从头梳理。 计算机在接电之后运行的是基本输入输出系统 BIOS，大伙儿知道，BIOS 是位于主板上的一个小程序， 其所在的空间有限，代码量较少，功能受限，因此它不可能一人扛下所有的任务需求，也就是肯定不能充 当操作系统的角色（比如说让 BIOS 运行 QQ 是不可能的），必须采取控制权接力的方式，一步步地让处 理器执行更为复杂强大的指令，最终把处理器的使用权交给操作系统，这才让计算机走上了正轨，从而可 以完成各种复杂的功能，方便人们的工作和生活。采用接力式控制权交接，BIOS 只完成一些简单的检测 或初始化工作，然后找机会把处理器使用权交出去。交给谁呢？下一个接力棒的选手是 MBR，为了方便 BIOS 找到 MBR，MBR 必须在固定的位置等待，因此 MBR 位于整个硬盘最开始的扇区。 MBR 是主引导记录，Master 或 Main Boot Record，它存在于整个硬盘最开始的那个扇区，即 0 盘 0 道 1 扇区，这个扇区便称为 MBR 引导扇区。注意这里用 CHS 方式表示 MBR 引导扇区的地址，因此扇区 地址以 1 开始，顺便说一句，LBA 方式是以 0 为起始为扇区编址的，有关 CHS 和 LBA 的内容会在后面 章节介绍。一般情况下扇区大小是 512 字节，但大伙儿不要把这个当真理，有的硬盘扇区并不是 512 字节。



在 MBR 引导扇区中的内容是： （1）446 字节的引导程序及参数； （2）64 字节的分区表； （3）2 字节结束标记 0x55 和 0xaa。 在 MBR 引导扇区中存储引导程序，为的是从 BIOS 手中接过系统的控制权，也就是处理器的使用权。 任何一棒的接力都是由上一棒跳到下一棒，也就是上一棒得知道下一棒在哪里才能跳过去，否则权利还是 交不出去。BIOS 知道 MBR 在 0 盘 0 道 1 扇区，这是约定好的，因此它会将 0 盘 0 道 1 扇区中的 MBR 引 导程序加载到物理地址 0x7c00，然后跳过去执行，这样 BIOS 就把处理器使用权移交给 MBR 了。 既然 MBR 称为“主”引导程序，有“主”就得有“次”， MBR 的作用相当于下一棒的引导程序总 入口，BIOS 把控制权交给 MBR 就行了，由 MBR 从众多可能的接力选手中挑出合适的人选并交出系统控 制权，这个过程就是由“主引导程序”去找“次引导程序”，这么说的意思是“次引导程序”不止一个。 也许您会问，为什么 BIOS 不直接把控制权交给“次引导程序”？原因是 BIOS 受限于其主板上的存储空 间，代码量有限，本身的工作还做不过来呢，因此心有余而力不足。好啦，下面开始下一轮的系统控制权 接力。不要忘了，MBR 引导扇区中除了引导程序外，还有 64 字节大小的分区表，里面是分区信息。分区 表中每个分区表项占 16 字节，因此 MBR 分区表中可容纳 4 个分区，这 4 个分区就是“次引导程序”的 候选人群，MBR 引导程序开始遍历这 4 个分区，想找到合适的人选并把系统控制权交给他。 通常情况下这个“次引导程序”就是操作系统提供的加载器，因此 MBR 引导程序的任务就是把控制 权交给操作系统加载器，由该加载器完成操作系统的自举，最终使控制权交付给操作系统内核。但是各分 区都有可能存在操作系统，MBR 也不知道操作系统在哪里，它甚至不知道分区上的二进制 01 串是指令， 还是普通数据，好吧，它根本分不清楚上面的是什么，谈何权利交接呢。 为了让 MBR 知道哪里有操作系统，我们在分区时，如果想在某个分区中安装操作系统，就用分区工 具将该分区设置为活动分区，设置活动分区的本质就是把分区表中该分区对应的分区表项中的活动标记为 0x80。MBR 知道“活动分区”意味着该分区中存在操作系统，这也是约定好的。活动分区标记位于分区 表项中最开始的 1 字节（有关分区内容，后面介绍分区的章节中会细说），其值要么为 0x80，要么为 0， 其他值都是非法的。0x80 表示此分区上有引导程序，0 表示没引导程序，该分区不可引导。MBR 在分析 分区表时通过辨识“活动分区”的标记 0x80 开始找活动分区，如果找到了，就将 CPU 使用权交给此分区 上的引导程序，此引导程序通常是内核加载器，下面就直接以它为例。 “控制权交接”是处理器从“上一棒选手”跳到“下一棒选手”来完成的，内核加载器的入口地址是这里所 说的“下一棒选手”，但是内核加载器在哪里呢？虽然分区那么大，但 MBR 最想去看的是内核加载器，不想盲 目地看看。因此您想到了，为了 MBR 方便找到活动分区上的内核加载器，内核加载器的入口地址也必须在固定 的位置，这个位置就是各分区最开始的扇区，这也是约定好的。这个“各分区起始的扇区”中存放的是操作系统 引导程序—内核加载器，因此该扇区称为操作系统引导扇区，其中的引导程序（内核加载器）称为操作系统 引导记录 OBR，即 OS Boot Record，此扇区也称为 OBR 引导扇区。在 OBR 扇区的前 3 个字节存放了跳转指令， 这同样是约定，因此 MBR 找到活动分区后，就大胆主动跳到活动分区 OBR 引导扇区的起始处，该起始处的跳 转指令马上将处理器带入操作系统引导程序，从此 MBR 完成了交接工作，以后便是内核的天下了。 不过 OBR 中开头的跳转指令跳往的目标地址并不固定，这是由所创建的文件系统决定的，对于 FAT32 文件系统来说，此跳转指令会跳转到本扇区偏移 0x5A 字节的操作系统引导程序处。不管跳转目标地址是 多少，总之那里通常是操作系统的内核加载器。 计算机历史中向来把兼容性放在首位，这才是计算机蒸蒸日上的原因。OBR 是从 DBR 遗留下来的， 要想了解 OBR，还是先从了解 DBR 开始。DBR 是 DOS Boot Record，也就是 DOS 操作系统的引导记录 （程序），DBR 中的内容大概是： （1）跳转指令，使 MBR 跳转到引导代码； （2）厂商信息、DOS 版本信息； （3）BIOS 参数块 BPB，即 BIOS Parameter Block；



（4）操作系统引导程序； （5）结束标记 0x55 和 0xaa。 在 DOS 时代只有 4 个分区，不存在扩展分区，这 4 个分区都相当于主分区，所以各主分区最开始的扇 区称为 DBR 引导扇区。后来有了扩展分区之后，无论分区是主分区，还是逻辑分区，为了兼容，分区最开 始的扇区都作为 DOS 引导扇区。但是其他操作系统如 UNIX，Linux 等为了兼容 MBR 也传承了这个习俗， 都将各分区最开始的扇区作为自己的引导扇区，在里面存放自己操作系统的引导程序。由于现在这个“分区 最开始的扇区”引导的操作系统类型太多了，而且 DOS 还退出历史舞台了，所以 DBR 也称为 OBR。 这里提到了扩展分区就不得不提到 EBR。当初为了解决分区数量限制的问题才有了扩展分区，EBR 是扩展分区中为了兼容 MBR 才提出的概念，主要是兼容 MBR 中的分区表。分区是用分区表来描述的， MBR 中有分区表，扩展分区中的是一个个的逻辑分区，因此扩展分区中也要有分区表，为扩展分区存储 分区表的扇区称为 EBR，即 Expand Boot Record，从名字上看就知道它是为了“兼容”而“扩展”出来的 结构，兼容的内容是分区表，因此它与 MBR 结构相同，只是位置不同，EBR 位于各子扩展分区中最开始 的扇区（注意，各主分区和各逻辑分区中最开始的扇区是操作系统引导扇区），理论上 MBR 只有 1 个， EBR 有无数个。有关扩展分区的内容还是要参见后面有关分区的章节，那里介绍得更细致。 现在总结一下。 EBR 与 MBR 结构相同，但位置和数量都不同，整个硬盘只有 1 个 MBR，其位于整个硬盘最开始的 扇区—0 道 0 道 1 扇区。而 EBR 可有无数个，具体位置取决于扩展分区的分配情况，总之是位于各子扩 展分区最开始的扇区，如果此处不明白子扩展分区是什么，到了以后跟踪分区的章节中大伙儿就会明白。OBR 其实就是 DBR，指的都是操作系统引导程序，位于各分区（主分区或逻辑分区）最开始的扇区，访扇区称为 操作系统引导扇区，即 OBR 引导扇区。OBR 的数量与分区数有关，等于主分区数加逻辑分区数之和，友情提 示：一个子扩展分区中只包含 1 个逻辑分区。 MBR 和 EBR 是分区工具创建维护的，不属于操作系统管理的范围，因此操作系统不可以往里面写东 西，注意这里所说的是“不可以”，其实操作系统是有能力读写任何地址的，只是如果这样做的话会破坏 “系统控制权接力赛”所使用的数据，下次开机后就无法启动了。OBR 是各分区（主分区或逻辑分区）最 开始的扇区，因此属于操作系统管理。 DBR、OBR、MBR、EBR 都包含引导程序，因此它们都称为引导扇区，只要该扇区中存在可执行的 程序，该扇区就是可引导扇区。若该扇区位于整个硬盘最开始的扇区，并且以 0x55 和 0xaa 结束，BIOS 就认为该扇区中存在 MBR，该扇区就是 MBR 引导扇区。若该扇区位于各分区最开始的扇区，并且以 0x55 和 0xaa 结束，MBR 就认为该扇区中有操作系统引导程序 OBR，该扇区就是 OBR 引导扇区。 DBR、OBR、MBR、EBR 结构中都有引导代码和结束标记 0x55 和 0xaa，因此很多同学都容易把它 们搞混。不过它们最大的区别是分区表只在 MBR 和 EBR 中存在，DBR 或 OBR 中绝对没有分区表。MBR、 EBR、OBR 的位置关系如图

![image-20210223000646630](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/img/image-20210223000646630.png)

MBR 位于整个硬盘最开始的块，EBR 位于每个子扩展分区，各子扩展分区中只有一个逻辑分 区。MBR 和 EBR 位于分区之外的扇区，而 OBR 则属于主分区和逻辑分区最开始的扇区，每个主分区和逻 辑分区中都有 OBR 引导扇区。



# 参考资料

[《操作系统真相还原》](https://cdn.jsdelivr.net/gh/mikeygithub/jsDeliver@master/resource/pdf/操作系统真象还原.pdf)   


 